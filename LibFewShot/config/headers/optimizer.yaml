# not finished ****************************************************

## optimizer info
#optimizer:
#  name: Adam
#  kwargs:
#    lr: 0.01
#  other: ~
#    # emb_func: 0.001 # define lr OR
#    # another_part:    # define multi params
#    #   lr: 0.1
#    #   weight_decay: 0.5
#
#
## lr_scheduler info
#lr_scheduler:
#  name: StepLR
#  kwargs:
#    gamma: 1.0
#    step_size: 20
#
#warmup: 0 # set 0 to turn off warmup


# optimizer info
optimizer:
  name: SGD
  kwargs:
    params: model.parameters()
    lr: 0.35
    momentum: 0.9
    weight_decay: 5e-04
    nesterov: True
  other: ~
    # emb_func: 0.001 # define lr OR
    # another_part:    # define multi params
    #   lr: 0.1
    #   weight_decay: 0.5

# lr_scheduler info
lr_scheduler:
  name: MultiStepLR
  kwargs:
    base_lr: 0.35
    # iters_per_epoch: # len(trainloader)?
    max_epoch: 95
    multi_step: [30, 60, 90]
    gamma: 0.1
    warmup_epoch: 5

warmup: 1 # set 0 to turn off warmup

